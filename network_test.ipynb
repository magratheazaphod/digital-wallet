{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/IPython/core/magics/extension.py:47: UserWarning: %install_ext` is deprecated, please distribute your extension as a python package.\n",
      "  \"as a python package.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed autotime.py. To use it, type:\n",
      "  %load_ext autotime\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "%install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "%load_ext autotime\n",
    "from user_class import User, find_new_friends\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.61 ms\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'paymo_input/'\n",
    "batch_file = 'batch_payment.csv'\n",
    "stream_file = 'stream_payment.csv'\n",
    "batch_path = input_dir + batch_file\n",
    "stream_path = input_dir + stream_file\n",
    "\n",
    "test_file = 'batch_payment.csv'\n",
    "test_path = input_dir + test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "batch_dict = {}\n",
    "batch_dict['time'] = {}\n",
    "batch_dict['id1'] = {}\n",
    "batch_dict['id2'] = {}\n",
    "batch_dict['amount'] = {}\n",
    "batch_dict['message'] = {}\n",
    "\n",
    "with open(test_path, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for i, row in enumerate(reader):\n",
    "        batch_dict['time'][i] = row['time']\n",
    "        batch_dict['id1'][i] = row[' id1']\n",
    "        batch_dict['id2'][i] = row[' id2']\n",
    "        batch_dict['amount'][i] = row[' amount']\n",
    "        batch_dict['message'][i] = row[' message']\n",
    "        \n",
    "df_batch = pd.DataFrame.from_dict(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 326 ms\n"
     ]
    }
   ],
   "source": [
    "#dictionary columns are randomly ordered - reorder as expected\n",
    "df_batch = df_batch[['time','id1','id2','amount','message']]\n",
    "#df_stream = df_stream[['time','id1','id2','amount','message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.96 ms\n"
     ]
    }
   ],
   "source": [
    "givers = df_batch.groupby('id1')\n",
    "receivers = df_batch.groupby('id2')\n",
    "partners_1 = {}\n",
    "partners_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid key:  no. Even if the union were a matter of economic indifference\n",
      "Skipping invalid key:  and even if it were to be disadvantageous from the economic standpoint\n",
      "time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "## find all transactions where user <user_id> was giver, then find list of partners in those transactions\n",
    "for user_id,transactions in givers:\n",
    "    \n",
    "    #store list of all transaction partners as list (easiest type to extend later)\n",
    "    try:\n",
    "        partners_1[int(user_id)] = list(givers.get_group(user_id)['id2'].astype(int))\n",
    "   \n",
    "    #some lines of batch_payment.txt and stream_payment.txt are off - omit malformed entries\n",
    "    except (KeyError, ValueError) as BadLine:\n",
    "        print(\"Skipping invalid key:\",user_id)\n",
    "    \n",
    "## same as before for all transactions where <user_id> was receiver\n",
    "for user_id,transactions in receivers:\n",
    "    \n",
    "    #store list of all transaction partners as list (easiest type to extend later)\n",
    "    try: \n",
    "        partners_2[int(user_id)] = list(receivers.get_group(user_id)['id1'].astype(int))\n",
    "        \n",
    "    #some lines of batch_payment.txt and stream_payment.txt are off - omit malformed entries\n",
    "    except (KeyError, ValueError) as BadLine:\n",
    "        print(\"Skipping invalid key:\",user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.5 ms\n"
     ]
    }
   ],
   "source": [
    "## it's possible that some users only show up as givers and others only as receivers - combine to master list of all IDs\n",
    "## in actuality for the provided batch_payment.txt all users show up as givers at least once, but not safe to assume\n",
    "user_list_1 = np.array(list(partners_1.keys()))\n",
    "user_list_2 = np.array(list(partners_2.keys()))\n",
    "user_list = np.unique(np.concatenate([user_list_1,user_list_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "user_master_list = {}\n",
    "\n",
    "#cycle through all users and agglomerate partners from all transactions\n",
    "#conversion back and forth between list and numpy array is pretty fast\n",
    "#lists easier to append to, hence why stored as list, but also wanted to use numpy.unique function.\n",
    "for user_id in user_list:\n",
    "    \n",
    "    pp = []\n",
    "    \n",
    "    if user_id in partners_1.keys():\n",
    "        pp += partners_1[user_id]\n",
    "        \n",
    "    if user_id in partners_2.keys():\n",
    "        pp += partners_2[user_id]\n",
    "        \n",
    "    #reduce to (sorted) list of all unique partners\n",
    "    user_master_list[user_id] = User(user_id, list(np.unique(pp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building lists of connections of degree 2 for each user...\n"
     ]
    }
   ],
   "source": [
    "## use the find_new_friends function (stored in user_class.py) to supplement friend tiers down to level of interest\n",
    "#creating lists of friends down to 4th-degree connections takes about two minutes for 70,000 users on my macbook pro.\n",
    "tier_depth = 4\n",
    "\n",
    "#successively add tiers of friendship to every user in user_master_list\n",
    "## this takes the longest of any part of the program - about an hour in total.\n",
    "for tier in range(2,tier_depth+1):\n",
    "    \n",
    "    print(\"Building lists of connections of degree\", tier, \"for each user...\")\n",
    "    \n",
    "    for user_id, user_data in user_master_list.items():\n",
    "        user_data.friends[tier] = find_new_friends(user_master_list,user_data,tier)\n",
    "            \n",
    "print(\"Done. Connections of degree n accessible via User.friends[n]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "## create forward lookup ##\n",
    "## for each user, dictionary dos links a user id with the level of friendship\n",
    "for user_id, user_data in user_master_list.items():\n",
    "    user_data.build_dos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.6 ms\n"
     ]
    }
   ],
   "source": [
    "#first test - have these people had a transaction with each other in the batch data set?\n",
    "def test1(id1,id2):\n",
    "    \n",
    "    #this being python, the following line doesn't take up new memory - just a shorthand\n",
    "    user_dos = user_master_list[id1].dos\n",
    "    \n",
    "    if id2 in user_dos.keys():\n",
    "        if user_dos[id2] == 1:\n",
    "            return 'trusted'\n",
    "    return 'unverified'\n",
    "\n",
    "#second test - is the transaction partner either a 1st or 2nd degree connection?    \n",
    "def test2(id1,id2):\n",
    "    \n",
    "    #this being python, the following line doesn't take up new memory - just a shorthand\n",
    "    user_dos = user_master_list[id1].dos\n",
    "    \n",
    "    if id2 in user_dos.keys():\n",
    "        if user_dos[id2] in range (1,3):\n",
    "            return 'trusted'\n",
    "    return 'unverified'\n",
    "    \n",
    "#third test - is the transaction partner at least a 4th degree connection?    \n",
    "def test3(id1,id2):\n",
    "\n",
    "    #this being python, the following line doesn't take up new memory - just a shorthand\n",
    "    user_dos = user_master_list[id1].dos\n",
    "\n",
    "    if id2 in user_dos.keys():\n",
    "        if user_dos[id2] in range(1,5):\n",
    "            return 'trusted'\n",
    "    return 'unverified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "## Now load in second half of data set - this time we choose to flag transactions as verified or unverified.\n",
    "stream_dict = {}\n",
    "stream_dict['time'] = {}\n",
    "stream_dict['id1'] = {}\n",
    "stream_dict['id2'] = {}\n",
    "stream_dict['amount'] = {}\n",
    "stream_dict['message'] = {}\n",
    "\n",
    "with open(stream_path, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for i, row in enumerate(reader):\n",
    "        stream_dict['time'][i] = row['time']\n",
    "        stream_dict['id1'][i] = row[' id1']\n",
    "        stream_dict['id2'][i] = row[' id2']\n",
    "        stream_dict['amount'][i] = row[' amount']\n",
    "        stream_dict['message'][i] = row[' message']\n",
    "        \n",
    "df_stream = pd.DataFrame.from_dict(stream_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>message</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.32</td>\n",
       "      <td>52575</td>\n",
       "      <td>1120</td>\n",
       "      <td>Spam</td>\n",
       "      <td>2016-11-02 09:49:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.45</td>\n",
       "      <td>47424</td>\n",
       "      <td>5995</td>\n",
       "      <td>Food for üåΩ üòé</td>\n",
       "      <td>2016-11-02 09:49:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.99</td>\n",
       "      <td>76352</td>\n",
       "      <td>64866</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2016-11-02 09:49:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.48</td>\n",
       "      <td>20449</td>\n",
       "      <td>1552</td>\n",
       "      <td>LoveWins</td>\n",
       "      <td>2016-11-02 09:49:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.94</td>\n",
       "      <td>48676</td>\n",
       "      <td>19395</td>\n",
       "      <td>Jeffs still fat</td>\n",
       "      <td>2016-11-02 09:49:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount     id1     id2            message                 time\n",
       "0   25.32   52575    1120              Spam   2016-11-02 09:49:29\n",
       "1   19.45   47424    5995      Food for üåΩ üòé   2016-11-02 09:49:29\n",
       "2   14.99   76352   64866          Clothing   2016-11-02 09:49:29\n",
       "3   13.48   20449    1552          LoveWins   2016-11-02 09:49:29\n",
       "4   29.94   48676   19395   Jeffs still fat   2016-11-02 09:49:29"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.99 ms\n"
     ]
    }
   ],
   "source": [
    "df_stream.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            1120\n",
       "1            5995\n",
       "2           64866\n",
       "3            1552\n",
       "4           19395\n",
       "5           45177\n",
       "6           16725\n",
       "7            8306\n",
       "8           24692\n",
       "9           66022\n",
       "10           5637\n",
       "11           5448\n",
       "12          59830\n",
       "13           9013\n",
       "14           2942\n",
       "15           3940\n",
       "16           3197\n",
       "17           5524\n",
       "18          13233\n",
       "19          49196\n",
       "20          33106\n",
       "21           2844\n",
       "22          24068\n",
       "23          26032\n",
       "24           3827\n",
       "25           3081\n",
       "26          24675\n",
       "27          21442\n",
       "28          32471\n",
       "29          47752\n",
       "            ...  \n",
       "2993519     48063\n",
       "2993520      7015\n",
       "2993521      5199\n",
       "2993522     10096\n",
       "2993523      9298\n",
       "2993524     11303\n",
       "2993525      3832\n",
       "2993526     13925\n",
       "2993527     33400\n",
       "2993528     32430\n",
       "2993529      3031\n",
       "2993530        14\n",
       "2993531     26160\n",
       "2993532     22694\n",
       "2993533      2908\n",
       "2993534      6256\n",
       "2993535     80358\n",
       "2993536     17053\n",
       "2993537     26631\n",
       "2993538        59\n",
       "2993539     73642\n",
       "2993540     11765\n",
       "2993541     38399\n",
       "2993542      4282\n",
       "2993543      9977\n",
       "2993544      6199\n",
       "2993545     22803\n",
       "2993546     46349\n",
       "2993547     13929\n",
       "2993548     17545\n",
       "Name: id2, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 929 ms\n"
     ]
    }
   ],
   "source": [
    "df_stream['id2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "('id2', 'occurred at index amount')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2138\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2139\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2140\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3338)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3041)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3820)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index._bin_search (pandas/index.c:9309)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unorderable types: numpy.ndarray() < str()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1bc3cac933f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df_stream['test2'] = pd.Series('unverified', index=df_stream.index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df_stream['test3'] = pd.Series('unverified', index=df_stream.index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test4'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4131\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4132\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4133\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4227\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4228\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4229\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4230\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4231\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-1bc3cac933f2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df_stream['test2'] = pd.Series('unverified', index=df_stream.index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df_stream['test3'] = pd.Series('unverified', index=df_stream.index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test4'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0;31m# python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: ('id2', 'occurred at index amount')"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.8 ms\n"
     ]
    }
   ],
   "source": [
    "## create output columns\n",
    "#df_stream['test1'] = df_stream.apply(lambda x: test1(int(x['id1']), int(x['id2'])), axis=1)\n",
    "#df_stream['test2'] = pd.Series('unverified', index=df_stream.index)\n",
    "#df_stream['test3'] = pd.Series('unverified', index=df_stream.index)\n",
    "df_stream['test4'] = df_stream.apply(lambda x: int(x['id2']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.94 ms\n"
     ]
    }
   ],
   "source": [
    "test3(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "## new approach - try to create a connectivity matrix - then, can figure out second-tier neighbors and such by multiplying matrix\n",
    "# by itself\n",
    "## conveniently, the list of users already ranges from 0 to 77,359 without gaps\n",
    "## therefore, can use usernumbers directly as row/column indices in connectivity matrix\n",
    "\n",
    "## takes about two minutes on 2016 macbook pro with 16GB of ram to convert to sparse matrix.\n",
    "\n",
    "n_users = len(user_master_list.keys())\n",
    "connectivity = np.zeros([n_users,n_users])\n",
    "\n",
    "for user_id, user_data in user_master_list.items():\n",
    "    for ff in user_data.friends[1]:\n",
    "        #connections are bi-directional, so we fill in two spots in the connectivity matrix.\n",
    "        connectivity[user_id,ff] = 1\n",
    "        connectivity[ff,user_id] = 1\n",
    "        \n",
    "#multiplying 100k by 100k numpy matrices too taxing - try sparse matrices.\n",
    "csp = sp.csr_matrix(connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#credit to Philipp Singer for his excellent tutorial on how to save the output of big matrix\n",
    "#multiplication to disk: http://www.philippsinger.info/?p=464\n",
    "l = n_users\n",
    " \n",
    "f = tb.open_file('product_2.h5', 'w')\n",
    "filters = tb.Filters(complevel=5, complib='blosc')\n",
    "out = f.create_carray(f.root, 'data', tb.Float32Atom(), shape=(l, l), filters=filters)\n",
    " \n",
    "bl = 1000 #this is the number of rows we calculate each loop\n",
    "b = csp.tocsc() #we slice b on columns, csc improves performance\n",
    " \n",
    "#slice by row\n",
    "for i in range(0, l, bl):\n",
    "    out[:,i:min(i+bl, l)] = (csp.dot(b[:,i:min(i+bl, l)])).toarray()\n",
    " \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2, ..., 4997, 4998, 4999]),)\n",
      "(77360,)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "(array([   0,    1,    2, ..., 4993, 4997, 4999]),)\n",
      "(77360,)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "(array([   0,    1,    2, ..., 4993, 4998, 4999]),)\n",
      "(77360,)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "(array([   0,    1,    2, ..., 4996, 4997, 4999]),)\n",
      "(77360,)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4e8f958cef4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.11 s\n"
     ]
    }
   ],
   "source": [
    "h5 = tb.open_file('product_2.h5', 'r')\n",
    "a = h5.root.data\n",
    "\n",
    "## the advantage of this system is that only one row gets loaded into memory at a time -\n",
    "# although we are saving a list of second-tier connections\n",
    "for user_id in range(10):\n",
    "    row = a[user_id,:] \n",
    "    user_master_list[user_id].friends[2] = list(np.nonzero(row))\n",
    "    print(len(user_master_list[user_id].friends[2]))\n",
    "    time.sleep(2)\n",
    "    \n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 737 ¬µs\n"
     ]
    }
   ],
   "source": [
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' üá®üá¥üá®üá¥üá®üá¥üá®üá¥üëçüèºüéâ '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## BIG PROBLEM - SKIPPED OVER A BUNCH OF ENTRIES\n",
    "batch_dict['message'][377592]\n",
    "#print(len(batch_dict['message'].keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
