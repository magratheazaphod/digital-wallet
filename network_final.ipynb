{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Production version of code for Insight Data Engineers program.\n",
    "\n",
    "# Overall strategy - define module \"account\" which contains a list of \"contacts\"\n",
    "# Contacts are saved as Python dictionary, using account number as key and the \"tier\" level as value\n",
    "# \"tier\" being the shorthand for the number of degrees of separation.\n",
    "# Since Python dictionaries are extremely fast (equivalent to hash tables), should be able to flag transaction fast\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Paths to data files\n",
    "input_dir = 'paymo_input/'\n",
    "batch_file = 'batch_payment.csv'\n",
    "stream_file = 'stream_payment.csv'\n",
    "batch_path = input_dir + batch_file\n",
    "stream_path = input_dir + stream_file\n",
    "\n",
    "test_file = 'batch_test_2.csv'\n",
    "test_path = input_dir + test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## first hurdle - PayMo messages can include commas, and therefore using pandas csv_read fails due to inconsistent number of columns.\n",
    "## current compromise is to use DictReader instead, which truncates Message at first comma\n",
    "## best solution likely involves regular expressions, but not analyzing messages for the time being anyway\n",
    "\n",
    "#takes about 30 seconds to load the 3 million lines each of batch_payment and stream_payment on my macbook pro.\n",
    "\n",
    "batch_dict = {}\n",
    "batch_dict['time'] = {}\n",
    "batch_dict['id1'] = {}\n",
    "batch_dict['id2'] = {}\n",
    "batch_dict['amount'] = {}\n",
    "batch_dict['message'] = {}\n",
    "\n",
    "with open(batch_path) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for i, row in enumerate(reader):\n",
    "        batch_dict['time'][i] = row['time']\n",
    "        batch_dict['id1'][i] = row[' id1']\n",
    "        batch_dict['id2'][i] = row[' id2']\n",
    "        batch_dict['amount'][i] = row[' amount']\n",
    "        batch_dict['message'][i] = row[' message']\n",
    "        \n",
    "df_batch = pd.DataFrame.from_dict(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## repeat the above - load in data from stream_payment and turn into pandas dataframe.\n",
    "stream_dict = {}\n",
    "stream_dict['time'] = {}\n",
    "stream_dict['id1'] = {}\n",
    "stream_dict['id2'] = {}\n",
    "stream_dict['amount'] = {}\n",
    "stream_dict['message'] = {}\n",
    "\n",
    "with open(stream_path) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for i, row in enumerate(reader):\n",
    "        stream_dict['time'][i] = row['time']\n",
    "        stream_dict['id1'][i] = row[' id1']\n",
    "        stream_dict['id2'][i] = row[' id2']\n",
    "        stream_dict['amount'][i] = row[' amount']\n",
    "        stream_dict['message'][i] = row[' message']\n",
    "        \n",
    "df_stream = pd.DataFrame.from_dict(stream_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dictionary columns are randomly ordered - reorder as expected\n",
    "df_batch = df_batch[['time','id1','id2','amount','message']]\n",
    "df_stream = df_stream[['time','id1','id2','amount','message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for convenience, let's call the id1 users 'givers' and id2 users 'receivers'\n",
    "#strategy is to use the pandas groupby command to obtain list of all partners in transactions where <user_id> is giver\n",
    "#repeat for transactions where <user_id> is receiver, then combine into single list\n",
    "givers = df_batch.groupby('id1')\n",
    "receivers = df_batch.groupby('id2')\n",
    "partners_1 = {}\n",
    "partners_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid key:  no. Even if the union were a matter of economic indifference\n",
      "Skipping invalid key:  and even if it were to be disadvantageous from the economic standpoint\n"
     ]
    }
   ],
   "source": [
    "## find all transactions where user <user_id> was giver, then find list of partners in those transactions\n",
    "for user_id,transactions in givers:\n",
    "    \n",
    "    #store list of all transaction partners as numpy array\n",
    "    try:\n",
    "        partners_1[int(user_id)] = np.array(givers.get_group(user_id)['id2'].astype(int))\n",
    "   \n",
    "    #some lines of batch_payment.txt and stream_payment.txt are off - omit malformed entries\n",
    "    except (KeyError, ValueError) as BadLine:\n",
    "        print(\"Skipping invalid key:\",user_id)\n",
    "    \n",
    "## same as before for all transactions where <user_id> was receiver\n",
    "for user_id,transactions in receivers:\n",
    "    \n",
    "    #store list of all transaction partners as numpy array\n",
    "    try: \n",
    "        partners_2[int(user_id)] = np.array(givers.get_group(user_id)['id1'].astype(int))\n",
    "        \n",
    "    #some lines of batch_payment.txt and stream_payment.txt are off - omit malformed entries\n",
    "    except (KeyError, ValueError) as BadLine:\n",
    "        print(\"Skipping invalid key:\",user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## it's possible that some users only show up as givers and others only as receivers - combine to master list of all IDs\n",
    "## in actuality for the provided batch_payment.txt all users show up as givers at least once, but not safe to assume\n",
    "user_list_1 = np.array(list(partners_1.keys()))\n",
    "user_list_2 = np.array(list(partners_2.keys()))\n",
    "user_list = np.unique(np.concatenate([user_list_1,user_list_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_master_list = {}\n",
    "\n",
    "#cycle through all users and agglomerate partners from all transactions\n",
    "#conversion back and forth between list and numpy array is pretty fast\n",
    "#lists easier to append to, hence why stored as list, but also wanted to use numpy.unique function.\n",
    "for user_id in user_list:\n",
    "    \n",
    "    pp = []\n",
    "    \n",
    "    if user_id in partners_1.keys():\n",
    "        pp += partners_1[user_id]\n",
    "        \n",
    "    if user_id in partners_2.keys():\n",
    "        pp += partners_2[user_id]\n",
    "        \n",
    "    #reduce to (sorted) list of all unique partners\n",
    "    user_master_list[user_id] = User(user_id, list(np.unique(pp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use the find_new_friends function (stored in user_class.py) to supplement friend tiers down to level of interest\n",
    "#creating lists of friends down to 4th-degree connections takes about two minutes for 70,000 users on my macbook pro.\n",
    "tier_depth = 4\n",
    "\n",
    "#successively add tiers of friendship to every user in user_master_list\n",
    "for tier in range(2,tier_depth+1):\n",
    "    print(\"Building lists of connections of degree\", tier, \"for each user...\")\n",
    "    for user_id, user_info in user_master_list.items():\n",
    "        user_info.friends[tier] = find_new_friends(user_master_list,user_info,tier)\n",
    "        \n",
    "print(\"Done. Connections of degree n accessible via User.friends[n]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
